{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import transformers\n",
    "# from tqdm import tqdm\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 测试 Bert Model\n",
    "1. 初始化tokenizer和Bert model，设置用于测试的text\n",
    "2. 基于pytorch执行bert推理，输出概率最高的10个词\n",
    "3. 保存输出信息，用来和之后转换过的模型进行对比\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BERT_PATH = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n",
    "model = BertForMaskedLM.from_pretrained(BERT_PATH, return_dict = True)\n",
    "text = \"The capital of France, \" + tokenizer.mask_token + \", contains the Eiffel Tower.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids: \n",
      " tensor([[  101,  1996,  3007,  1997,  2605,  1010,   103,  1010,  3397,  1996,\n",
      "          1041, 13355,  2884,  3578,  1012,   102]])\n",
      "output shape:  torch.Size([1, 16, 30522])\n",
      "model test topk10 output:\n",
      "The capital of France, paris, contains the Eiffel Tower.\n",
      "The capital of France, lyon, contains the Eiffel Tower.\n",
      "The capital of France, lille, contains the Eiffel Tower.\n",
      "The capital of France, toulouse, contains the Eiffel Tower.\n",
      "The capital of France, marseille, contains the Eiffel Tower.\n",
      "The capital of France, orleans, contains the Eiffel Tower.\n",
      "The capital of France, strasbourg, contains the Eiffel Tower.\n",
      "The capital of France, nice, contains the Eiffel Tower.\n",
      "The capital of France, cannes, contains the Eiffel Tower.\n",
      "The capital of France, versailles, contains the Eiffel Tower.\n",
      "****************************************\n",
      "pytorch with bin model running time: 0.02531918330005283\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
    "mask_index = torch.where(encoded_input[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "print(\"input ids: \\n\",encoded_input[\"input_ids\"])\n",
    "\n",
    "# warm up\n",
    "for i in range(5):\n",
    "    output = model(**encoded_input)\n",
    "start_time = time.perf_counter()\n",
    "for i in range(10):\n",
    "    output = model(**encoded_input)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(\"output shape: \", output[0].shape)\n",
    "logits = output.logits\n",
    "softmax = F.softmax(logits, dim = -1)\n",
    "mask_word = softmax[0, mask_index, :]\n",
    "top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]\n",
    "print(\"model test topk10 output:\")\n",
    "for token in top_10:\n",
    "    word = tokenizer.decode([token])\n",
    "    new_sentence = text.replace(tokenizer.mask_token, word)\n",
    "    print(new_sentence)\n",
    "print('*' * 40)\n",
    "print(\"pytorch with bin model running time:\", (end_time-start_time)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving inputs and output to case_data.npz ...\n",
      "position id:  tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]],\n",
      "       dtype=torch.int32)\n",
      "input_id shape:  (1, 16)\n",
      "saved input ids: \n",
      " [[  101  1996  3007  1997  2605  1010   103  1010  3397  1996  1041 13355\n",
      "   2884  3578  1012   102]]\n"
     ]
    }
   ],
   "source": [
    "# save inputs and output\n",
    "print(\"Saving inputs and output to case_data.npz ...\")\n",
    "position_ids = torch.arange(0, encoded_input['input_ids'].shape[1]).int().view(1, -1)\n",
    "print(\"position id: \",position_ids)\n",
    "input_ids=encoded_input['input_ids'].int().detach().numpy()\n",
    "token_type_ids=encoded_input['token_type_ids'].int().detach().numpy()\n",
    "print(\"input_id shape: \",input_ids.shape)\n",
    "# save data\n",
    "npz_file = BERT_PATH + '/case_data.npz'\n",
    "np.savez(npz_file,\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            logits=output[0].detach().numpy())\n",
    "\n",
    "data = np.load(npz_file)\n",
    "print(\"saved input ids: \\n\", data['input_ids'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 将模型转换为ONNX格式\n",
    "使用torch.onnx.export() 进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported at  bert-base-uncased/model.onnx\n"
     ]
    }
   ],
   "source": [
    "# convert model to onnx\n",
    "model.eval()\n",
    "export_model_path = BERT_PATH + \"/model.onnx\"\n",
    "opset_version = 12\n",
    "symbolic_names = {0: 'batch_size', 1: 'max_seq_len'}\n",
    "torch.onnx.export(  model,                                            \n",
    "                    args=tuple(encoded_input.values()),               # model input (or a tuple for multiple inputs)\n",
    "                    f=export_model_path,                              # where to save the model (can be a file or file-like object)\n",
    "                    opset_version=opset_version,                      # the ONNX version to export the model to\n",
    "                    do_constant_folding=False,                        # whether to execute constant folding for optimization\n",
    "                    input_names=['input_ids',                         # the model's input names\n",
    "                                'attention_mask',\n",
    "                                'token_type_ids'],\n",
    "                    output_names=['logits'],                          # the model's output names\n",
    "                    dynamic_axes={'input_ids': symbolic_names,        # variable length axes\n",
    "                                'attention_mask' : symbolic_names,\n",
    "                                'token_type_ids' : symbolic_names,\n",
    "                                'logits' : symbolic_names})\n",
    "print(\"Model exported at \", export_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 使用onnxruntime进行onnx推理\n",
    "与pytorch和tensorrt的推理时间相对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnxruntime version: 1.16.3\n",
      "onnxruntime device: GPU\n"
     ]
    }
   ],
   "source": [
    "# 检查设备是否为GPU\n",
    "print(\"onnxruntime version:\", ort.__version__)\n",
    "print(\"onnxruntime device:\", ort.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert SUCCESS!!!!!!\n",
      "****************************************\n",
      "pytorch with bin model running time: 0.017354312099632806\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "session = ort.InferenceSession(export_model_path)\n",
    "# 执行推理\n",
    "# warmup\n",
    "for i in range(5):\n",
    "    outputs = session.run(['logits'], {'input_ids': encoded_input['input_ids'].numpy(),\n",
    "                                    'attention_mask': encoded_input['attention_mask'].numpy(),\n",
    "                                   'token_type_ids': encoded_input['token_type_ids'].numpy()})[0]\n",
    "start_time = time.perf_counter()\n",
    "for i in range(10):\n",
    "    outputs = session.run(['logits'], {'input_ids': encoded_input['input_ids'].numpy(),\n",
    "                                    'attention_mask': encoded_input['attention_mask'].numpy(),\n",
    "                                   'token_type_ids': encoded_input['token_type_ids'].numpy()})[0]\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "# 检查转换后的模型的精度损失情况\n",
    "required_precission = 1e-4\n",
    "precesion_loss = np.abs(outputs - data['logits'])\n",
    "boolean_mask = precesion_loss > required_precission\n",
    "if(len(np.where(boolean_mask)[0]) > 0):\n",
    "    print(\"Convert ERROR!\")\n",
    "else:\n",
    "    print(\"Convert SUCCESS!!!!!!\")\n",
    "print('*' * 40)\n",
    "print(\"pytorch with bin model running time:\", (end_time-start_time)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简化ONNX model\n",
    "使用onnxsim库，进行常量折叠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!onnxsim bert-base-uncased/model.onnx bert-base-uncased/model-sim.onnx --overwrite-input-shape input_ids:1,12 token_type_ids:1,12 attention_mask:1,12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104911/2324552632.py:9: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = max_ws\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/01/2024-15:13:31] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "network.num_layers 1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104911/2324552632.py:19: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config=config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/01/2024-15:14:01] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[02/01/2024-15:14:01] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[02/01/2024-15:14:01] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[02/01/2024-15:14:01] [TRT] [W] - 133 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[02/01/2024-15:14:01] [TRT] [W] - 53 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[02/01/2024-15:14:01] [TRT] [W] - 1 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n"
     ]
    }
   ],
   "source": [
    "def build_engine(model_file, max_ws=512*1024*1024, fp16=True):\n",
    "    print(\"building engine\")\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "\n",
    "    config = builder.create_builder_config()\n",
    "    if fp16:\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "    config.max_workspace_size = max_ws\n",
    "    \n",
    "    explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    network = builder.create_network(explicit_batch)\n",
    "    with trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        with open(model_file, 'rb') as model:\n",
    "            parsed = parser.parse(model.read())\n",
    "            print(\"network.num_layers\", network.num_layers)\n",
    "            #last_layer = network.get_layer(network.num_layers - 1)\n",
    "            #network.mark_output(last_layer.get_output(0))\n",
    "            engine = builder.build_engine(network, config=config)\n",
    "            return engine\n",
    "            \n",
    "engine = build_engine(\"bert-base-uncased/model-sim.onnx\")\n",
    "# save the paln model\n",
    "BERT_PATH = 'bert-base-uncased'\n",
    "plan_path = BERT_PATH +'/model.plan'\n",
    "with open(plan_path, 'wb') as f:\n",
    "    f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_PATH = 'bert-base-uncased'\n",
    "plan_path = BERT_PATH +'/model.plan'\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "runtime = trt.Runtime(TRT_LOGGER)\n",
    "with open(plan_path, 'rb') as f:\n",
    "    engine_bytes = f.read()\n",
    "    engine = runtime.deserialize_cuda_engine(engine_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493568"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=encoded_input['input_ids'].numpy().astype(np.int32)\n",
    "attention_mask = encoded_input['attention_mask'].numpy().astype(np.int32)\n",
    "token_type_ids = encoded_input['token_type_ids'].numpy().astype(np.int32)\n",
    "bert_output = np.empty((1, 16, 30522), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n",
      "int32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.dtype)\n",
    "print(attention_mask.dtype)\n",
    "print(token_type_ids.dtype)\n",
    "print(bert_output.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "d_input_ids = cuda.mem_alloc(batch_size * input_ids.nbytes)\n",
    "d_token_type_ids = cuda.mem_alloc(batch_size * token_type_ids.nbytes)\n",
    "d_attention_mask = cuda.mem_alloc(batch_size * attention_mask.nbytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.nbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_output = cuda.mem_alloc(batch_size * bert_output.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1953408"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_output.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = [int(d_input_ids), int(d_token_type_ids), int(d_attention_mask), int(d_output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = cuda.Stream()\n",
    "# Transfer input data from python buffers to device(GPU)\n",
    "cuda.memcpy_htod_async(d_input_ids, input_ids, stream)\n",
    "cuda.memcpy_htod_async(d_token_type_ids, token_type_ids, stream)\n",
    "cuda.memcpy_htod_async(d_attention_mask, attention_mask, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/01/2024-15:23:40] [TRT] [W] The enqueue() method has been deprecated when used with engines built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. Please use enqueueV2() instead.\n",
      "[02/01/2024-15:23:40] [TRT] [W] Also, the batchSize argument passed into this function has no effect on changing the input shapes. Please use setBindingDimensions() function to change input shapes instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104911/898248060.py:1: DeprecationWarning: Use execute_async_v2 instead.\n",
      "  bert_context.execute_async(batch_size, bindings, stream.handle, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_context.execute_async(batch_size, bindings, stream.handle, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh_async(bert_output, d_output, stream)\n",
    "stream.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 30522)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.tensor(bert_output)\n",
    "pred_output_softmax = torch.nn.Softmax()(pred)\n",
    "_, predicted = torch.max(pred_output_softmax, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -7.0117188,  -7.1171875,  -7.03125  , ...,  -6.5976562,\n",
       "          -6.3359375,  -4.7929688],\n",
       "        [-11.7734375, -12.1796875, -12.0078125, ..., -11.       ,\n",
       "          -9.875    , -10.9296875],\n",
       "        [ -9.109375 ,  -9.8984375,  -9.2734375, ...,  -9.34375  ,\n",
       "          -7.7851562, -10.765625 ],\n",
       "        ...,\n",
       "        [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ]]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], dtype=torch.int64), tensor([], dtype=torch.int64))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(predicted != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
